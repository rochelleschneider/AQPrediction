---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# AQPrediction

<!-- badges: start -->
<!-- badges: end -->

The goal of this repo is to demonstrate spatio-temporal prediction models to estimate levels of air pollution.

The input dataset is an Excel [file](https://drive.google.com/open?id=14GvlMCBLR9FQ_BsCeg0tj-pb1AadXr3G3gKPnrfm8gg) provided as part of the [OpenGeoHub Summer School 2019](https://opengeohub.org/summer_school_2019).

We'll use these packages

```{r}
suppressPackageStartupMessages({
  library(dplyr)
  library(sf)
})
```

And read-in the input data as follows

```{r, warning=FALSE, message=FALSE}
train = readxl::read_excel("SpatialPrediction.xlsx", sheet = 1)
covar = readxl::read_excel("SpatialPrediction.xlsx", sheet = 2)
locat = readxl::read_excel("SpatialPrediction.xlsx", sheet = 3)
# times = readxl::read_excel("SpatialPrediction.xlsx", sheet = 4) # what is this?
targt = readxl::read_excel("SpatialPrediction.xlsx", sheet = 5)
```

The objective is to fill the NA values in the `targt` data:

```{r}
targt[1:3]
```


Let's do some data cleaning and plot the data:

```{r}
d = inner_join(train, covar)
d = inner_join(d, locat)
dsf = sf::st_as_sf(d, coords = c("X", "Y"), crs = 4326)
summary(dsf)
mapview::mapview(dsf %>% sample_n(1000))
```

A simple model:

```{r}
m = lm(PM10 ~ humidity + temperature, data = d)
p = predict(object = m, newdata = d)
plot(d$PM10, p)
cor(d$PM10, p)^2
```

A simple linear model can explain ~3% of the variability in PM10 levels, not great!

